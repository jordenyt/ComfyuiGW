{
  "23": {
    "inputs": {
      "unet_name": "wan2.1-i2v-14b-480p-Q6_K.gguf",
      "device": "cuda:0",
      "virtual_vram_gb": 0,
      "use_other_vram": false,
      "expert_mode_allocations": ""
    },
    "class_type": "UnetLoaderGGUFDisTorchMultiGPU",
    "_meta": {
      "title": "UnetLoaderGGUFDisTorchMultiGPU"
    }
  },
  "26": {
    "inputs": {
      "image": "sdsketch_6922_240828140158.jpg",
      "resize": true,
      "width": 640,
      "height": 640,
      "repeat": 1,
      "keep_proportion": true,
      "divisible_by": 16,
      "mask_channel": "alpha",
      "background_color": ""
    },
    "class_type": "LoadAndResizeImage",
    "_meta": {
      "title": "Load & Resize Image"
    }
  },
  "27": {
    "inputs": {
      "text": [
        "86",
        0
      ],
      "clip": [
        "21:1",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "28": {
    "inputs": {
      "text": "overexposure, deformed, mutation, blurry, flashing",
      "clip": [
        "21:1",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "31": {
    "inputs": {
      "samples": [
        "85:9",
        0
      ],
      "vae": [
        "21:2",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "32": {
    "inputs": {
      "shift": 8,
      "model": [
        "23",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "39": {
    "inputs": {
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "i2v_wan",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": false,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "31",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine üé•üÖ•üÖóüÖ¢"
    }
  },
  "40": {
    "inputs": {
      "width": [
        "26",
        2
      ],
      "height": [
        "26",
        3
      ],
      "length": 161,
      "batch_size": 1,
      "positive": [
        "27",
        0
      ],
      "negative": [
        "28",
        0
      ],
      "vae": [
        "21:2",
        0
      ],
      "clip_vision_output": [
        "41",
        0
      ],
      "start_image": [
        "26",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "WanImageToVideo"
    }
  },
  "41": {
    "inputs": {
      "crop": "none",
      "clip_vision": [
        "21:0",
        0
      ],
      "image": [
        "26",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "49": {
    "inputs": {
      "sage_attention": "sageattn_qk_int8_pv_fp16_triton",
      "model": [
        "84",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "50": {
    "inputs": {
      "weight": 2,
      "model": [
        "49",
        0
      ],
      "latent": [
        "40",
        2
      ]
    },
    "class_type": "WanVideoEnhanceAVideoKJ",
    "_meta": {
      "title": "WanVideo Enhance A Video (native)"
    }
  },
  "51": {
    "inputs": {
      "start_index": -1,
      "num_frames": 1,
      "images": [
        "31",
        0
      ]
    },
    "class_type": "GetImageRangeFromBatch",
    "_meta": {
      "title": "Get Image or Mask Range From Batch"
    }
  },
  "52": {
    "inputs": {
      "output_path": "",
      "filename_prefix": "api",
      "filename_delimiter": "_",
      "filename_number_padding": 4,
      "filename_number_start": "false",
      "extension": "jpg",
      "dpi": 300,
      "quality": 95,
      "optimize_image": "true",
      "lossless_webp": "false",
      "overwrite_mode": "false",
      "show_history": "false",
      "show_history_by_prefix": "false",
      "embed_workflow": "false",
      "show_previews": "false",
      "images": [
        "51",
        0
      ]
    },
    "class_type": "Image Save",
    "_meta": {
      "title": "Image Save"
    }
  },
  "84": {
    "inputs": {
      "lora_name": "WAN21\\l3z_kiss.safetensors",
      "strength": 0.7000000000000002,
      "blocks_type": "all",
      "model": [
        "32",
        0
      ]
    },
    "class_type": "HunyuanVideoLoraLoader",
    "_meta": {
      "title": "Hunyuan Video LoRA Loader"
    }
  },
  "86": {
    "inputs": {
      "api_key": "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",
      "system_prompt": "You are a helper to generate video prompt from picture description and user input elements.  The video prompt should not include the picture description but only need to state the motion of background, action/movement of subject and camera movement. The output should not have fore-word and explanation of the prompt.",
      "user_message_box": [
        "92",
        0
      ],
      "model": "deepseek/deepseek-chat-v3-0324:free",
      "web_search": false,
      "cheapest": false,
      "fastest": true,
      "temperature": 1,
      "pdf_engine": "auto"
    },
    "class_type": "OpenRouterNode",
    "_meta": {
      "title": "OpenRouter LLM Node (Text/Multi-Image/PDF)"
    }
  },
  "87": {
    "inputs": {
      "model": "MiaoshouAI/Florence-2-large-PromptGen-v2.0",
      "precision": "fp16",
      "attention": "eager",
      "convert_to_safetensors": false
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "88": {
    "inputs": {
      "text_input": "",
      "task": "more_detailed_caption",
      "fill_mask": false,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 20,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 159148526306525,
      "image": [
        "26",
        0
      ],
      "florence2_model": [
        "87",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "89": {
    "inputs": {
      "a": "\\n Picture description: \\n",
      "b": [
        "88",
        2
      ]
    },
    "class_type": "JWStringConcat",
    "_meta": {
      "title": "String Concatenate"
    }
  },
  "90": {
    "inputs": {
      "a": "\\n User input element: \\n",
      "b": [
        "91",
        0
      ]
    },
    "class_type": "JWStringConcat",
    "_meta": {
      "title": "String Concatenate"
    }
  },
  "91": {
    "inputs": {
      "text": "kissing, hugging, cleavage, medium sized breast, 10 seconds long"
    },
    "class_type": "ttN text",
    "_meta": {
      "title": "text"
    }
  },
  "92": {
    "inputs": {
      "a": [
        "89",
        0
      ],
      "b": [
        "90",
        0
      ]
    },
    "class_type": "JWStringConcat",
    "_meta": {
      "title": "String Concatenate"
    }
  },
  "94": {
    "inputs": {
      "text_0": "- Gentle sway of church curtains from a soft breeze  \n- The couple turns toward each other, their hands intertwining  \n- Warm light gradually brightens on their faces as they lean in for a tender kiss  \n- His hand glides up to caress her cheek during the embrace, fingers brushing her veil  \n- She arches slightly into the hug, drawing him closer, cleavage pressing against his chest  \n- Slow push-in camera movement emphasizing the intimacy  \n- Veil flutters as they separate, eyes locking with loving smiles",
      "text": [
        "86",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text üêç"
    }
  },
  "21:0": {
    "inputs": {
      "clip_name": "clip_vision_h_fp8_e4m3fn.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "21:1": {
    "inputs": {
      "clip_name": "t5xxl_um_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "cpu"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "21:2": {
    "inputs": {
      "vae_name": "Wan2_1_VAE_bf16.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "85:0": {
    "inputs": {
      "Number": "14"
    },
    "class_type": "Int",
    "_meta": {
      "title": "Int"
    }
  },
  "85:1": {
    "inputs": {
      "Number": "0.4"
    },
    "class_type": "Float",
    "_meta": {
      "title": "Float"
    }
  },
  "85:2": {
    "inputs": {
      "expression": "round(a * b)",
      "a": [
        "85:0",
        0
      ],
      "b": [
        "85:1",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression üêç"
    }
  },
  "85:3": {
    "inputs": {
      "expression": "a - round(a * b)",
      "a": [
        "85:0",
        0
      ],
      "b": [
        "85:1",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression üêç"
    }
  },
  "85:7": {
    "inputs": {
      "lora_name": "WAN21\\Wan21_CausVid_14B_T2V_lora_rank32.safetensors",
      "strength": 0.25000000000000006,
      "blocks_type": "all",
      "model": [
        "50",
        0
      ]
    },
    "class_type": "HunyuanVideoLoraLoader",
    "_meta": {
      "title": "Hunyuan Video LoRA Loader"
    }
  },
  "85:8": {
    "inputs": {
      "seed": 103156893102496,
      "steps": [
        "85:2",
        0
      ],
      "cfg": 6,
      "sampler_name": "euler_ancestral",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "50",
        0
      ],
      "positive": [
        "40",
        0
      ],
      "negative": [
        "40",
        1
      ],
      "latent_image": [
        "40",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "85:9": {
    "inputs": {
      "seed": 982067027679273,
      "steps": [
        "85:3",
        0
      ],
      "cfg": 1,
      "sampler_name": "euler_ancestral",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "85:7",
        0
      ],
      "positive": [
        "40",
        0
      ],
      "negative": [
        "40",
        1
      ],
      "latent_image": [
        "85:8",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  }
}