{
  "23": {
    "inputs": {
      "unet_name": "Wan2.1-VACE-14B-Q6_K.gguf",
      "device": "cuda:0",
      "virtual_vram_gb": 0,
      "use_other_vram": false,
      "expert_mode_allocations": ""
    },
    "class_type": "UnetLoaderGGUFDisTorchMultiGPU",
    "_meta": {
      "title": "UnetLoaderGGUFDisTorchMultiGPU"
    }
  },
  "26": {
    "inputs": {
      "image": "sdsketch_11329_250522231715.jpg",
      "resize": true,
      "width": 640,
      "height": 640,
      "repeat": 1,
      "keep_proportion": true,
      "divisible_by": 16,
      "mask_channel": "alpha",
      "background_color": ""
    },
    "class_type": "LoadAndResizeImage",
    "_meta": {
      "title": "Load & Resize Image"
    }
  },
  "27": {
    "inputs": {
      "text": "slim Asian woman, with long dark brown hair, selfie, collarbone, medium sized breasts, cleavage, denim shorts, looking at viewer",
      "clip": [
        "21:1",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "28": {
    "inputs": {
      "text": "overexposure, deformed, mutation, blurry, flashing, changing face, speaking, makeup, smile",
      "clip": [
        "21:1",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "31": {
    "inputs": {
      "samples": [
        "201",
        0
      ],
      "vae": [
        "21:2",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "32": {
    "inputs": {
      "shift": 8.000000000000002,
      "model": [
        "224",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "39": {
    "inputs": {
      "frame_rate": [
        "233",
        0
      ],
      "loop_count": 0,
      "filename_prefix": "iv2v_wan_vace_pose_mask",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": false,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "31",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine 🎥🅥🅗🅢"
    }
  },
  "49": {
    "inputs": {
      "sage_attention": "sageattn_qk_int8_pv_fp8_cuda++",
      "model": [
        "32",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "50": {
    "inputs": {
      "weight": 2.0000000000000004,
      "model": [
        "203",
        0
      ],
      "latent": [
        "186",
        2
      ]
    },
    "class_type": "WanVideoEnhanceAVideoKJ",
    "_meta": {
      "title": "WanVideo Enhance A Video (native)"
    }
  },
  "186": {
    "inputs": {
      "width": [
        "26",
        2
      ],
      "height": [
        "26",
        3
      ],
      "length": [
        "236",
        0
      ],
      "batch_size": 1,
      "strength": 1,
      "positive": [
        "27",
        0
      ],
      "negative": [
        "28",
        0
      ],
      "vae": [
        "21:2",
        0
      ],
      "control_video": [
        "223",
        0
      ],
      "control_masks": [
        "223",
        1
      ],
      "reference_image": [
        "26",
        0
      ]
    },
    "class_type": "WanVaceToVideo",
    "_meta": {
      "title": "WanVaceToVideo"
    }
  },
  "201": {
    "inputs": {
      "trim_amount": [
        "186",
        3
      ],
      "samples": [
        "237:9",
        0
      ]
    },
    "class_type": "TrimVideoLatent",
    "_meta": {
      "title": "TrimVideoLatent"
    }
  },
  "203": {
    "inputs": {
      "self_structural": 1,
      "self_temporal": 1,
      "cross_structural": 1.2,
      "cross_temporal": 1.3,
      "model": [
        "49",
        0
      ]
    },
    "class_type": "UNetTemporalAttentionMultiply",
    "_meta": {
      "title": "UNetTemporalAttentionMultiply"
    }
  },
  "204": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "23",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "207": {
    "inputs": {
      "start_index": 0,
      "original_images": [
        "228",
        0
      ],
      "replacement_images": [
        "208",
        0
      ],
      "original_masks": [
        "231",
        0
      ],
      "replacement_masks": [
        "210",
        0
      ]
    },
    "class_type": "ReplaceImagesInBatch",
    "_meta": {
      "title": "Replace Images In Batch"
    }
  },
  "208": {
    "inputs": {
      "image": "sdsketch_11323_250522231952.jpg",
      "resize": true,
      "width": [
        "26",
        2
      ],
      "height": [
        "26",
        3
      ],
      "repeat": 1,
      "keep_proportion": false,
      "divisible_by": 1,
      "mask_channel": "alpha",
      "background_color": ""
    },
    "class_type": "LoadAndResizeImage",
    "_meta": {
      "title": "Load & Resize Image"
    }
  },
  "209": {
    "inputs": {
      "width": [
        "26",
        2
      ],
      "height": [
        "26",
        3
      ],
      "red": 0,
      "green": 0,
      "blue": 0
    },
    "class_type": "Image Blank",
    "_meta": {
      "title": "Image Blank"
    }
  },
  "210": {
    "inputs": {
      "channel": "red",
      "image": [
        "209",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "220": {
    "inputs": {
      "image": "sdsketch_11329_250522231715.jpg",
      "resize": true,
      "width": [
        "208",
        2
      ],
      "height": [
        "208",
        3
      ],
      "repeat": 1,
      "keep_proportion": false,
      "divisible_by": 1,
      "mask_channel": "alpha",
      "background_color": ""
    },
    "class_type": "LoadAndResizeImage",
    "_meta": {
      "title": "Load & Resize Image"
    }
  },
  "221": {
    "inputs": {
      "start_index": 16,
      "original_images": [
        "207",
        0
      ],
      "replacement_images": [
        "220",
        0
      ],
      "original_masks": [
        "207",
        1
      ],
      "replacement_masks": [
        "210",
        0
      ]
    },
    "class_type": "ReplaceImagesInBatch",
    "_meta": {
      "title": "Replace Images In Batch"
    }
  },
  "222": {
    "inputs": {
      "image": "sdsketch_11336_250523003411.jpg",
      "resize": true,
      "width": [
        "220",
        2
      ],
      "height": [
        "220",
        3
      ],
      "repeat": 1,
      "keep_proportion": false,
      "divisible_by": 1,
      "mask_channel": "alpha",
      "background_color": ""
    },
    "class_type": "LoadAndResizeImage",
    "_meta": {
      "title": "Load & Resize Image"
    }
  },
  "223": {
    "inputs": {
      "start_index": 32,
      "original_images": [
        "221",
        0
      ],
      "replacement_images": [
        "222",
        0
      ],
      "original_masks": [
        "221",
        1
      ],
      "replacement_masks": [
        "210",
        0
      ]
    },
    "class_type": "ReplaceImagesInBatch",
    "_meta": {
      "title": "Replace Images In Batch"
    }
  },
  "224": {
    "inputs": {
      "lora_name": "WAN21\\wan-nsfw-e14-fixed.safetensors",
      "strength": 0.5000000000000001,
      "blocks_type": "all",
      "model": [
        "204",
        0
      ]
    },
    "class_type": "HunyuanVideoLoraLoader",
    "_meta": {
      "title": "Hunyuan Video LoRA Loader"
    }
  },
  "227": {
    "inputs": {
      "width": [
        "26",
        2
      ],
      "height": [
        "26",
        3
      ],
      "red": 127,
      "green": 127,
      "blue": 127
    },
    "class_type": "Image Blank",
    "_meta": {
      "title": "Image Blank"
    }
  },
  "228": {
    "inputs": {
      "amount": [
        "236",
        0
      ],
      "image": [
        "227",
        0
      ]
    },
    "class_type": "RepeatImageBatch",
    "_meta": {
      "title": "RepeatImageBatch"
    }
  },
  "229": {
    "inputs": {
      "width": [
        "26",
        2
      ],
      "height": [
        "26",
        3
      ],
      "red": 255,
      "green": 255,
      "blue": 255
    },
    "class_type": "Image Blank",
    "_meta": {
      "title": "Image Blank"
    }
  },
  "230": {
    "inputs": {
      "amount": 1,
      "image": [
        "229",
        0
      ]
    },
    "class_type": "RepeatImageBatch",
    "_meta": {
      "title": "RepeatImageBatch"
    }
  },
  "231": {
    "inputs": {
      "channel": "red",
      "image": [
        "230",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "233": {
    "inputs": {
      "value": 16
    },
    "class_type": "PrimitiveFloat",
    "_meta": {
      "title": "Float"
    }
  },
  "236": {
    "inputs": {
      "value": 81
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "Int"
    }
  },
  "21:1": {
    "inputs": {
      "clip_name": "t5xxl_um_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "cpu"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "21:2": {
    "inputs": {
      "vae_name": "Wan2_1_VAE_bf16.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "237:0": {
    "inputs": {
      "Number": "10"
    },
    "class_type": "Int",
    "_meta": {
      "title": "Int"
    }
  },
  "237:1": {
    "inputs": {
      "Number": "0.3"
    },
    "class_type": "Float",
    "_meta": {
      "title": "Float"
    }
  },
  "237:2": {
    "inputs": {
      "expression": "round(a * b)",
      "a": [
        "237:0",
        0
      ],
      "b": [
        "237:1",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression 🐍"
    }
  },
  "237:3": {
    "inputs": {
      "expression": "a - round(a * b)",
      "a": [
        "237:0",
        0
      ],
      "b": [
        "237:1",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression 🐍"
    }
  },
  "237:7": {
    "inputs": {
      "lora_name": "WAN21\\Wan21_CausVid_14B_T2V_lora_rank32.safetensors",
      "strength": 0.25,
      "blocks_type": "all",
      "model": [
        "50",
        0
      ]
    },
    "class_type": "HunyuanVideoLoraLoader",
    "_meta": {
      "title": "Hunyuan Video LoRA Loader"
    }
  },
  "237:8": {
    "inputs": {
      "seed": 872491008498603,
      "steps": [
        "237:2",
        0
      ],
      "cfg": 4,
      "sampler_name": "euler_ancestral",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "50",
        0
      ],
      "positive": [
        "186",
        0
      ],
      "negative": [
        "186",
        1
      ],
      "latent_image": [
        "186",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "237:9": {
    "inputs": {
      "seed": 860419600816617,
      "steps": [
        "237:3",
        0
      ],
      "cfg": 1,
      "sampler_name": "euler_ancestral",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "237:7",
        0
      ],
      "positive": [
        "186",
        0
      ],
      "negative": [
        "186",
        1
      ],
      "latent_image": [
        "237:8",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  }
}