{
    "v2v_upscale_VFI_api": {
        "prompt_workflow": "v2v_upscale_VFI_api.json",
        "fields": {
            "video": "376.inputs.video",
            "force_rate": "376.inputs.force_rate"
        },
        "descriptions": "Upscale and Up-rate Video",
        "inputs": {
            "video": {"type": "video", "default": null},
            "force_rate": {"type": "integer", "default": 16}
        }
    },
    "v2v_color_match_api": {
        "prompt_workflow": "v2v_color_match_api.json",
        "fields": {
            "video": "12.inputs.video",
            "ref_image": "11.inputs.image"
        },
        "descriptions": "Match video to reference image.",
        "inputs": {
            "video": {"type": "video", "default": null},
            "ref_image": {"type": "image", "default": null}
        }
    },
    "iv2v_liveportrait_api": {
        "prompt_workflow": "iv2v_liveportrait_video_api.json",
        "fields": {
            "video": "146.inputs.video",
            "drv_video": "8.inputs.video",
            "force_rate": "146.inputs.force_rate",
            "frame_load_cap": "146.inputs.frame_load_cap"
        },
        "descriptions": "Expression Transfer with LivePortrait.",
        "inputs": {
            "video": {"type": "video", "default": null},
            "drv_video": {"type": "video", "default": null},
            "force_rate": {"type": "integer", "default": 16},
            "frame_load_cap": {"type": "integer", "default": 0}
        }
    },
    "video_get_mask_api": {
        "prompt_workflow": "video_get_mask_api.json",
        "descriptions": "Get mask from video by prompt",
        "fields": {
            "src_video": "9.inputs.video",
            "size": ["10.inputs.width", "10.inputs.height"],
            "force_rate": "9.inputs.force_rate",
            "frame_load_cap": "9.inputs.frame_load_cap",
            "mask_prompt_1": "3.inputs.prompt",
            "mask_threshold_1": "3.inputs.threshold",
            "mask_expand_1": "5.inputs.expand",
            "mask_prompt_2": "4.inputs.prompt",
            "mask_threshold_2": "4.inputs.threshold",
            "mask_expand_2": "6.inputs.expand"
        },
        "inputs": {
            "src_video": {"type":"video", "default":null},
            "size": {"type":"integer", "default":640},
            "force_rate": {"type":"integer", "default":16},
            "frame_load_cap": {"type":"integer", "default":0},
            "mask_prompt_1": {"type":"string", "default":"face, hair, neck"},
            "mask_threshold_1": {"type":"float", "default":0.3},
            "mask_expand_1": {"type":"integer", "default":30},
            "mask_prompt_2": {"type":"string", "default":"man, woman"},
            "mask_threshold_2": {"type":"float", "default":0.1},
            "mask_expand_2": {"type":"integer", "default":10}
        }
    },
    "video_get_pose_api": {
        "prompt_workflow": "video_get_pose_api.json",
        "descriptions": "Get mask from video by prompt",
        "fields": {
            "src_video": "9.inputs.video",
            "size": ["10.inputs.width", "10.inputs.height"],
            "force_rate": "9.inputs.force_rate",
            "frame_load_cap": "9.inputs.frame_load_cap",
            "detect_face": "14.inputs.detect_face"
        },
        "inputs": {
            "src_video": {"type":"video", "default":null},
            "size": {"type":"integer", "default":640},
            "force_rate": {"type":"integer", "default":16},
            "frame_load_cap": {"type":"integer", "default":0},
            "detect_face": {"type":"string", "default":"disable"}
        }
    },
    "extract_frame_api": {
        "prompt_workflow": "extract_frame_api.json",
        "descriptions": "Get an image from video by index",
        "fields": {
            "src_video": "1.inputs.video",
            "force_rate": "1.inputs.force_rate",
            "index": "6.inputs.Number",
            "size": ["5.inputs.width", "5.inputs.height"],
            "divisible_by": "5.inputs.divisible_by"
        },
        "inputs": {
            "src_video": {"type":"video", "default":null},
            "force_rate": {"type":"integer", "default":16},
            "index": {"type":"integer", "default":0},
            "size": {"type":"integer", "default":640},
            "divisible_by": {"type":"integer", "default":16}
        }
    },
    "video_replace_audio_api": {
        "prompt_workflow": "video_audio_replace_api.json",
        "fields": {
            "video": "1.inputs.video",
            "audio": "6.inputs.audio"
        },
        "descriptions": "Replace audio track of a video",
        "inputs": {
            "video": {"type": "video", "default": null},
            "audio": {"type": "audio", "default": null}
        }
    },
    "video_save_mp4_api": {
        "prompt_workflow": "v2v_save_mp4_api.json",
        "fields": {
            "video": "1.inputs.video"
        },
        "descriptions": "Convert video to MP4/YUV420p/H.264 ",
        "inputs": {
            "video": {"type": "video", "default": null}
        }
    }
}