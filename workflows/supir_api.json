{
  "5": {
    "inputs": {
      "use_tiled_vae": true,
      "encoder_tile_size": 1024,
      "decoder_tile_size": 1024,
      "encoder_dtype": "bf16",
      "SUPIR_VAE": [
        "21",
        1
      ],
      "image": [
        "31",
        0
      ]
    },
    "class_type": "SUPIR_first_stage",
    "_meta": {
      "title": "SUPIR First Stage (Denoiser)"
    }
  },
  "7": {
    "inputs": {
      "seed": 285115455055814,
      "steps": 10,
      "cfg_scale_start": 1,
      "cfg_scale_end": 1,
      "EDM_s_churn": 5,
      "s_noise": 1.0030000000000001,
      "DPMPP_eta": 1,
      "control_scale_start": 1,
      "control_scale_end": 0.9,
      "restore_cfg": 1,
      "keep_model_loaded": false,
      "sampler": "RestoreEDMSampler",
      "sampler_tile_size": 1024,
      "sampler_tile_stride": 512,
      "SUPIR_model": [
        "21",
        0
      ],
      "latents": [
        "11",
        0
      ],
      "positive": [
        "9",
        0
      ],
      "negative": [
        "9",
        1
      ]
    },
    "class_type": "SUPIR_sample",
    "_meta": {
      "title": "SUPIR Sampler"
    }
  },
  "9": {
    "inputs": {
      "positive_prompt": "1girl, long brown hair",
      "negative_prompt": "bad quality, blurry, messy",
      "SUPIR_model": [
        "21",
        0
      ],
      "latents": [
        "5",
        2
      ]
    },
    "class_type": "SUPIR_conditioner",
    "_meta": {
      "title": "SUPIR Conditioner"
    }
  },
  "10": {
    "inputs": {
      "use_tiled_vae": true,
      "decoder_tile_size": 1024,
      "SUPIR_VAE": [
        "21",
        1
      ],
      "latents": [
        "7",
        0
      ]
    },
    "class_type": "SUPIR_decode",
    "_meta": {
      "title": "SUPIR Decode"
    }
  },
  "11": {
    "inputs": {
      "use_tiled_vae": true,
      "encoder_tile_size": 1024,
      "encoder_dtype": "bf16",
      "SUPIR_VAE": [
        "5",
        0
      ],
      "image": [
        "5",
        1
      ]
    },
    "class_type": "SUPIR_encode",
    "_meta": {
      "title": "SUPIR Encode"
    }
  },
  "14": {
    "inputs": {
      "method": "mkl",
      "strength": 1,
      "image_ref": [
        "27",
        0
      ],
      "image_target": [
        "10",
        0
      ]
    },
    "class_type": "ColorMatch",
    "_meta": {
      "title": "Color Match"
    }
  },
  "21": {
    "inputs": {
      "supir_model": "SupIR\\SUPIR-v0Q_fp16.safetensors",
      "fp8_unet": false,
      "diffusion_dtype": "bf16",
      "high_vram": false,
      "model": [
        "22",
        0
      ],
      "clip": [
        "22",
        1
      ],
      "vae": [
        "22",
        2
      ]
    },
    "class_type": "SUPIR_model_loader_v2",
    "_meta": {
      "title": "SUPIR Model Loader (v2)"
    }
  },
  "22": {
    "inputs": {
      "ckpt_name": "sdxlTurbo\\dreamshaperXL_lightningDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "27": {
    "inputs": {
      "image": "received_6012624482172001.jpeg",
      "resize": false,
      "width": 2560,
      "height": 2560,
      "repeat": 1,
      "keep_proportion": true,
      "divisible_by": 1,
      "mask_channel": "alpha",
      "background_color": "black",
      "upload": "image"
    },
    "class_type": "LoadAndResizeImage",
    "_meta": {
      "title": "Load & Resize Image"
    }
  },
  "29": {
    "inputs": {
      "output_path": "",
      "filename_prefix": "api",
      "filename_delimiter": "_",
      "filename_number_padding": 4,
      "filename_number_start": "false",
      "extension": "jpg",
      "dpi": 300,
      "quality": 95,
      "optimize_image": "true",
      "lossless_webp": "false",
      "overwrite_mode": "false",
      "show_history": "false",
      "show_history_by_prefix": "true",
      "embed_workflow": "true",
      "show_previews": "true",
      "images": [
        "14",
        0
      ]
    },
    "class_type": "Image Save",
    "_meta": {
      "title": "Image Save"
    }
  },
  "31": {
    "inputs": {
      "width": [
        "35",
        0
      ],
      "height": [
        "35",
        0
      ],
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 1,
      "crop": "disabled",
      "image": [
        "44",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "Resize Image"
    }
  },
  "35": {
    "inputs": {
      "expression": "sqrt(max(a,b)/min(a,b)) * c",
      "a": [
        "27",
        2
      ],
      "b": [
        "27",
        3
      ],
      "c": [
        "36",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression 🐍"
    }
  },
  "36": {
    "inputs": {
      "value": 2560
    },
    "class_type": "JWInteger",
    "_meta": {
      "title": "Integer"
    }
  },
  "37": {
    "inputs": {
      "boolean": [
        "47",
        0
      ],
      "on_true": [
        "27",
        0
      ],
      "on_false": [
        "41",
        0
      ]
    },
    "class_type": "easy ifElse",
    "_meta": {
      "title": "If else"
    }
  },
  "38": {
    "inputs": {
      "expression": "max(a, b) * 4",
      "a": [
        "27",
        2
      ],
      "b": [
        "27",
        3
      ],
      "c": [
        "36",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression 🐍"
    }
  },
  "41": {
    "inputs": {
      "width": 64,
      "height": 64,
      "upscale_method": "lanczos",
      "keep_proportion": true,
      "divisible_by": 1,
      "crop": "disabled",
      "image": [
        "27",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "Resize Image"
    }
  },
  "42": {
    "inputs": {
      "upscale_model": [
        "43",
        0
      ],
      "image": [
        "37",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "43": {
    "inputs": {
      "model_name": "4xNomos8kSCHAT-L.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "44": {
    "inputs": {
      "boolean": [
        "47",
        0
      ],
      "on_true": [
        "50",
        0
      ],
      "on_false": [
        "27",
        0
      ]
    },
    "class_type": "easy ifElse",
    "_meta": {
      "title": "If else"
    }
  },
  "47": {
    "inputs": {
      "comparison": "a > b",
      "a": [
        "35",
        0
      ],
      "b": [
        "38",
        0
      ]
    },
    "class_type": "easy compare",
    "_meta": {
      "title": "Compare"
    }
  },
  "50": {
    "inputs": {
      "facedetection": "retinaface_resnet50",
      "model": "GFPGANv1.4.pth",
      "visibility": 1,
      "codeformer_weight": 0,
      "image": [
        "42",
        0
      ]
    },
    "class_type": "ReActorRestoreFace",
    "_meta": {
      "title": "Restore Face 🌌 ReActor"
    }
  }
}